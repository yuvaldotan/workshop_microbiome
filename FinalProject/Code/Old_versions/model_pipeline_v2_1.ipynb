{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.special import softmax\n",
    "from scipy.optimize import minimize, LinearConstraint\n",
    "from scipy.spatial.distance import braycurtis\n",
    "import multiprocessing\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from imports import *\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# # adding Folder_2 to the system path\n",
    "# sys.path.insert(0, r'C:\\Users\\tomer\\Desktop\\BSc\\year3\\sem B\\workshop_microbiome\\code')\n",
    "# # sys.path.insert(0, r'C:\\Users\\yuvald\\Documents\\Uni\\סמסטר ב\\workshop_microbiome\\code')\n",
    "\n",
    "from imports import  *\n",
    "\n",
    "import social_model_class_v2\n",
    "reload(social_model_class_v2)\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.1,\n",
       " 0.010000000000000002,\n",
       " 0.0010000000000000002,\n",
       " 0.00010000000000000002,\n",
       " 1.0000000000000003e-05,\n",
       " 1.0000000000000004e-06,\n",
       " 1.0000000000000004e-07,\n",
       " 1.0000000000000005e-08,\n",
       " 1.0000000000000005e-09,\n",
       " 1.0000000000000006e-10,\n",
       " 1.0000000000000006e-11,\n",
       " 1.0000000000000006e-12,\n",
       " 1.0000000000000007e-13,\n",
       " 1.0000000000000008e-14,\n",
       " 1.0000000000000009e-15,\n",
       " 1.0000000000000008e-16,\n",
       " 1.000000000000001e-17,\n",
       " 1.000000000000001e-18,\n",
       " 1.000000000000001e-19,\n",
       " 1.0000000000000011e-20,\n",
       " 1.0000000000000012e-21,\n",
       " 1.0000000000000012e-22,\n",
       " 1.0000000000000013e-23,\n",
       " 1.0000000000000014e-24,\n",
       " 1.0000000000000014e-25,\n",
       " 1.0000000000000015e-26,\n",
       " 1.0000000000000015e-27,\n",
       " 1.0000000000000015e-28,\n",
       " 1.0000000000000016e-29,\n",
       " 1.0000000000000017e-30,\n",
       " 1.0000000000000016e-31,\n",
       " 1.0000000000000018e-32,\n",
       " 1.0000000000000018e-33,\n",
       " 1.0000000000000019e-34,\n",
       " 1.0000000000000019e-35,\n",
       " 1.000000000000002e-36,\n",
       " 1.0000000000000022e-37,\n",
       " 1.000000000000002e-38,\n",
       " 1.0000000000000022e-39,\n",
       " 1.0000000000000022e-40,\n",
       " 1.0000000000000023e-41,\n",
       " 1.0000000000000023e-42,\n",
       " 1.0000000000000025e-43,\n",
       " 1.0000000000000024e-44,\n",
       " 1.0000000000000025e-45,\n",
       " 1.0000000000000026e-46,\n",
       " 1.0000000000000026e-47,\n",
       " 1.0000000000000027e-48,\n",
       " 1.0000000000000028e-49]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = r\"train_data.csv\"\n",
    "metadata_path = r\"train_metadata.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Delta_t  \\space windowing$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomer\\Desktop\\BSc\\year3\\sem B\\workshop_microbiome\\Milestone2\\social_model_class_v2.py:295: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metadata_clean['collection_date'] = pd.to_datetime(metadata_clean['collection_date'])\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43msocial_model_class_v2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuperModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(model\u001b[38;5;241m.\u001b[39mmetadata_df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39misin(model\u001b[38;5;241m.\u001b[39mdata_df\u001b[38;5;241m.\u001b[39mindex))\n\u001b[0;32m      4\u001b[0m t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\tomer\\Desktop\\BSc\\year3\\sem B\\workshop_microbiome\\Milestone2\\social_model_class_v2.py:167\u001b[0m, in \u001b[0;36msuperModel.__init__\u001b[1;34m(self, data_path, metadata_path)\u001b[0m\n\u001b[0;32m    164\u001b[0m             futures\u001b[38;5;241m.\u001b[39mappend(executor\u001b[38;5;241m.\u001b[39msubmit(BaboonModel, baboon_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_df, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_df))\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fut \u001b[38;5;129;01min\u001b[39;00m futures:\n\u001b[1;32m--> 167\u001b[0m     baboon \u001b[38;5;241m=\u001b[39m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m                  \n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbaboons[baboon\u001b[38;5;241m.\u001b[39mbaboon_id] \u001b[38;5;241m=\u001b[39m baboon\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m61\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "model = social_model_class_v2.superModel(data_path, metadata_path)\n",
    "\n",
    "assert np.all(model.metadata_df.index.isin(model.data_df.index))\n",
    "t = time.time()\n",
    "model.baboons[\"Baboon_101\"].fit(np.zeros(61), 0)\n",
    "print(time.time() -t)\n",
    "model.baboons[\"Baboon_101\"].beta_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = social_model_class_v2.superModel(data_path, metadata_path)\n",
    "# model.alpha_ = np.array([0]*61)\n",
    "# for baboon in model.baboons.values():\n",
    "#     baboon.fit(0.11, np.zeros(61))\n",
    "\n",
    "# mat = np.array([baboon.beta_ for baboon in model.baboons.values()])\n",
    "\n",
    "# sns.heatmap(pd.DataFrame(mat,columns=baboon.data_I.columns, index = model.baboons.keys()), cmap='viridis')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross validation (4 - fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baboons = model.baboons\n",
    "dict_list = list(model.baboons.items())\n",
    "np.random.shuffle(dict_list)\n",
    "groups = [dict(group) for group in np.array_split(dict_list,4)]\n",
    "\n",
    "data_df = pd.read_csv(data_path, index_col=0)\n",
    "metadata_df = pd.read_csv(metadata_path, index_col=0)\n",
    "\n",
    "for i in range(4):\n",
    "    train_metatdata = metadata_df[~metadata_df[\"baboon_id\"].isin(groups[i].keys())]\n",
    "    train_data = data_df.loc[train_metatdata.index]\n",
    "    known_metadata = metadata_df[metadata_df['baboon_id'].isin(groups[i].keys())]\n",
    "    indicies = []\n",
    "    for baboon in groups[i].values():\n",
    "        indicies.extend(baboon.metadata_I.index[:10])\n",
    "\n",
    "    known_data = data_df.loc[indicies]\n",
    "    true_data = data_df.loc[known_metadata[~np.isin(known_metadata.index, indicies)].index]\n",
    "\n",
    "\n",
    "    train_data.to_csv(fr\".\\cross_val_data\\train_data_{i}.csv\")\n",
    "    train_metatdata.to_csv(fr\".\\cross_val_data\\train_metadata_{i}.csv\")\n",
    "    known_data.to_csv(fr\".\\cross_val_data\\known_data_{i}.csv\")\n",
    "    known_metadata.to_csv(fr\".\\cross_val_data\\known_metadata_{i}.csv\")\n",
    "    true_data.to_csv(fr\".\\cross_val_data\\true_data_{i}.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomer\\Desktop\\BSc\\year3\\sem B\\workshop_microbiome\\Milestone2\\social_model_class_v2.py:288: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metadata_clean['collection_date'] = pd.to_datetime(metadata_clean['collection_date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting 0\n",
      "new data added 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['sample_11411-TCGAAGACGTAT-396', 'sample_12051-AGTAGTTTCCTT-408',\\n       'sample_12051-TGGCGCACGGAC-408', 'sample_12049-CTAGAGCTCCCA-407',\\n       'sample_11413-CCTAGCCCTAGC-397', 'sample_11413-CCTGTGTTGGTG-397',\\n       'sample_12050-ACCGTCTTTCTC-407', 'sample_11406-GCGCGAATGGTG-394',\\n       'sample_12052-GTCACATCACGA-408', 'sample_11406-GCAGGGTCGAAC-394',\\n       'sample_12052-TCCGAGTCACCA-408', 'sample_12052-TTAAACCGCGCC-408',\\n       'sample_12052-TTGTAGCCGACA-408', 'sample_11413-CACTAGACCCAC-397',\\n       'sample_11411-GGCGCCATCTCT-396', 'sample_11407-TCGGTTACGCTG-394',\\n       'sample_12053-GATGCCTAATGA-409', 'sample_12052-TACAGCGCATAC-408',\\n       'sample_11408-TCACTGCTAGGA-395', 'sample_11408-TATGCTCTCTCA-395',\\n       'sample_11412-GTTCGGTGTCCA-397', 'sample_12050-TACATATCTACA-407',\\n       'sample_11407-TGCCAGACCACT-394', 'sample_11408-AGTCATCGAATG-395',\\n       'sample_12052-TATGCTCTCTCA-408', 'sample_11407-TCAGACCAACTG-394',\\n       'sample_12052-GGACTTCCAGCT-408', 'sample_12050-GCTTATTGCTTA-407',\\n       'sample_12052-CCTCGTCGTCAG-408', 'sample_11413-GCAGACGGAACC-397',\\n       'sample_11406-TAGTCTAAGGGT-394', 'sample_11410-ATCAATTGTCCT-396',\\n       'sample_11410-TCTGGGCATTGA-396', 'sample_12053-CTCCGAACAACA-409',\\n       'sample_11410-ACCCGGATTTCG-396', 'sample_11413-CTCCACATTCCT-397',\\n       'sample_11406-CATCAGTACGCC-394', 'sample_12049-CAGTAGCGATAT-407',\\n       'sample_11406-AACCCTAACTGG-394', 'sample_11408-CAGTGTCATGAA-395',\\n       'sample_11409-ACCATTACCATT-395'],\\n      dtype='object', name='sample')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\process.py\", line 261, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\tomer\\Desktop\\BSc\\year3\\sem B\\workshop_microbiome\\Milestone2\\social_model_class_v2.py\", line 86, in predict\n    return self.non_iterative_predictor(gamma, alpha)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\tomer\\Desktop\\BSc\\year3\\sem B\\workshop_microbiome\\Milestone2\\social_model_class_v2.py\", line 90, in non_iterative_predictor\n    D_I = self.weighted_mean(gamma, mask).values # is it equal to self.weighted_mean(gamma, mask).loc[mask].values?\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\tomer\\Desktop\\BSc\\year3\\sem B\\workshop_microbiome\\Milestone2\\social_model_class_v2.py\", line 122, in weighted_mean\n    res = self.data_I.loc[samples].copy()\n          ~~~~~~~~~~~~~~~^^^^^^^^^\n  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py\", line 1192, in __getitem__\n    return self._getitem_axis(maybe_callable, axis=axis)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py\", line 1421, in _getitem_axis\n    return self._getitem_iterable(key, axis=axis)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py\", line 1361, in _getitem_iterable\n    keyarr, indexer = self._get_listlike_indexer(key, axis)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py\", line 1559, in _get_listlike_indexer\n    keyarr, indexer = ax._get_indexer_strict(key, axis_name)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 6199, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"c:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 6248, in _raise_if_missing\n    raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\nKeyError: \"None of [Index(['sample_11411-TCGAAGACGTAT-396', 'sample_12051-AGTAGTTTCCTT-408',\\n       'sample_12051-TGGCGCACGGAC-408', 'sample_12049-CTAGAGCTCCCA-407',\\n       'sample_11413-CCTAGCCCTAGC-397', 'sample_11413-CCTGTGTTGGTG-397',\\n       'sample_12050-ACCGTCTTTCTC-407', 'sample_11406-GCGCGAATGGTG-394',\\n       'sample_12052-GTCACATCACGA-408', 'sample_11406-GCAGGGTCGAAC-394',\\n       'sample_12052-TCCGAGTCACCA-408', 'sample_12052-TTAAACCGCGCC-408',\\n       'sample_12052-TTGTAGCCGACA-408', 'sample_11413-CACTAGACCCAC-397',\\n       'sample_11411-GGCGCCATCTCT-396', 'sample_11407-TCGGTTACGCTG-394',\\n       'sample_12053-GATGCCTAATGA-409', 'sample_12052-TACAGCGCATAC-408',\\n       'sample_11408-TCACTGCTAGGA-395', 'sample_11408-TATGCTCTCTCA-395',\\n       'sample_11412-GTTCGGTGTCCA-397', 'sample_12050-TACATATCTACA-407',\\n       'sample_11407-TGCCAGACCACT-394', 'sample_11408-AGTCATCGAATG-395',\\n       'sample_12052-TATGCTCTCTCA-408', 'sample_11407-TCAGACCAACTG-394',\\n       'sample_12052-GGACTTCCAGCT-408', 'sample_12050-GCTTATTGCTTA-407',\\n       'sample_12052-CCTCGTCGTCAG-408', 'sample_11413-GCAGACGGAACC-397',\\n       'sample_11406-TAGTCTAAGGGT-394', 'sample_11410-ATCAATTGTCCT-396',\\n       'sample_11410-TCTGGGCATTGA-396', 'sample_12053-CTCCGAACAACA-409',\\n       'sample_11410-ACCCGGATTTCG-396', 'sample_11413-CTCCACATTCCT-397',\\n       'sample_11406-CATCAGTACGCC-394', 'sample_12049-CAGTAGCGATAT-407',\\n       'sample_11406-AACCCTAACTGG-394', 'sample_11408-CAGTGTCATGAA-395',\\n       'sample_11409-ACCATTACCATT-395'],\\n      dtype='object', name='sample')] are in the [index]\"\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m model\u001b[38;5;241m.\u001b[39madd_new_data(\u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcross_val_data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mknown_data_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcross_val_data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mknown_metadata_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew data added \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m predictions_noniterative \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m predictions_iterative \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(groups[i]\u001b[38;5;241m.\u001b[39mkeys(), iterative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     44\u001b[0m predictions_noniterative\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcross_val_data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpredictions_noniterative_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tomer\\Desktop\\BSc\\year3\\sem B\\workshop_microbiome\\Milestone2\\social_model_class_v2.py:248\u001b[0m, in \u001b[0;36msuperModel.predict\u001b[1;34m(self, baboons_to_predict, iterative)\u001b[0m\n\u001b[0;32m    245\u001b[0m         futures\u001b[38;5;241m.\u001b[39mappend(fut)\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fut \u001b[38;5;129;01min\u001b[39;00m futures:\n\u001b[1;32m--> 248\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([predictions, \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m])\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[1;32mc:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\tomer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['sample_11411-TCGAAGACGTAT-396', 'sample_12051-AGTAGTTTCCTT-408',\\n       'sample_12051-TGGCGCACGGAC-408', 'sample_12049-CTAGAGCTCCCA-407',\\n       'sample_11413-CCTAGCCCTAGC-397', 'sample_11413-CCTGTGTTGGTG-397',\\n       'sample_12050-ACCGTCTTTCTC-407', 'sample_11406-GCGCGAATGGTG-394',\\n       'sample_12052-GTCACATCACGA-408', 'sample_11406-GCAGGGTCGAAC-394',\\n       'sample_12052-TCCGAGTCACCA-408', 'sample_12052-TTAAACCGCGCC-408',\\n       'sample_12052-TTGTAGCCGACA-408', 'sample_11413-CACTAGACCCAC-397',\\n       'sample_11411-GGCGCCATCTCT-396', 'sample_11407-TCGGTTACGCTG-394',\\n       'sample_12053-GATGCCTAATGA-409', 'sample_12052-TACAGCGCATAC-408',\\n       'sample_11408-TCACTGCTAGGA-395', 'sample_11408-TATGCTCTCTCA-395',\\n       'sample_11412-GTTCGGTGTCCA-397', 'sample_12050-TACATATCTACA-407',\\n       'sample_11407-TGCCAGACCACT-394', 'sample_11408-AGTCATCGAATG-395',\\n       'sample_12052-TATGCTCTCTCA-408', 'sample_11407-TCAGACCAACTG-394',\\n       'sample_12052-GGACTTCCAGCT-408', 'sample_12050-GCTTATTGCTTA-407',\\n       'sample_12052-CCTCGTCGTCAG-408', 'sample_11413-GCAGACGGAACC-397',\\n       'sample_11406-TAGTCTAAGGGT-394', 'sample_11410-ATCAATTGTCCT-396',\\n       'sample_11410-TCTGGGCATTGA-396', 'sample_12053-CTCCGAACAACA-409',\\n       'sample_11410-ACCCGGATTTCG-396', 'sample_11413-CTCCACATTCCT-397',\\n       'sample_11406-CATCAGTACGCC-394', 'sample_12049-CAGTAGCGATAT-407',\\n       'sample_11406-AACCCTAACTGG-394', 'sample_11408-CAGTGTCATGAA-395',\\n       'sample_11409-ACCATTACCATT-395'],\\n      dtype='object', name='sample')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "\n",
    "baboons = model.baboons\n",
    "dict_list = list(model.baboons.items())\n",
    "np.random.shuffle(dict_list)\n",
    "groups = [dict(group) for group in np.array_split(dict_list,4)]\n",
    "metadata_df, data_df = social_model_class_v2.preprocessing(data_path, metadata_path)\n",
    "\n",
    "for i in range(4):\n",
    "    train_metatdata = metadata_df[~metadata_df[\"baboon_id\"].isin(groups[i].keys())]\n",
    "    train_data = data_df.loc[train_metatdata.index]\n",
    "    known_metadata = metadata_df[metadata_df['baboon_id'].isin(groups[i].keys())]\n",
    "    indicies = []\n",
    "    for baboon in groups[i].values():\n",
    "        indicies.extend(baboon.metadata_I.index[:10])\n",
    "\n",
    "    known_data = data_df.loc[indicies]\n",
    "    true_data = data_df.loc[known_metadata[~np.isin(known_metadata.index, indicies)].index]\n",
    "\n",
    "\n",
    "    train_data.to_csv(fr\".\\cross_val_data\\train_data_{i}.csv\")\n",
    "    train_metatdata.to_csv(fr\".\\cross_val_data\\train_metadata_{i}.csv\")\n",
    "    known_data.to_csv(fr\".\\cross_val_data\\known_data_{i}.csv\")\n",
    "    known_metadata.to_csv(fr\".\\cross_val_data\\known_metadata_{i}.csv\")\n",
    "    true_data.to_csv(fr\".\\cross_val_data\\true_data_{i}.csv\")\n",
    "    \n",
    "for i in range(4):\n",
    "    model = social_model_class_v2.superModel(fr\".\\cross_val_data\\train_data_{i}.csv\", fr\".\\cross_val_data\\train_metadata_{i}.csv\")\n",
    "    model.alpha_ = np.array([0]*61)\n",
    "    \n",
    "    cpus = max(1, min(multiprocessing.cpu_count() - 2, len(model.baboons)))\n",
    "    \n",
    "       # with ProcessPoolExecutor(cpus) as executor:\n",
    "    #     futures = [executor.submit(baboon.fit, model.alpha_) for baboon in model.baboons.values()]\n",
    "    #     for future in as_completed(futures):\n",
    "    #         pass\n",
    "    for baboon in model.baboons.values():\n",
    "        baboon.beta= np.random.rand(61)\n",
    "    print(f\"predicting {i}\")\n",
    "\n",
    "    model.add_new_data(fr\".\\cross_val_data\\known_data_{i}.csv\", fr\".\\cross_val_data\\known_metadata_{i}.csv\")\n",
    "\n",
    "    print(f\"new data added {i}\")\n",
    "    predictions_noniterative = model.predict(groups[i].keys(), iterative=False)\n",
    "    predictions_iterative = model.predict(groups[i].keys(), iterative=True)\n",
    "    predictions_noniterative.to_csv(fr\".\\cross_val_data\\predictions_noniterative_{i}.csv\")\n",
    "    predictions_iterative.to_csv(fr\".\\cross_val_data\\predictions_iterative_{i}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(10, 15))\n",
    "\n",
    "for i in range(4):\n",
    "    # Load data\n",
    "    predictions_noniterative = pd.read_csv(fr\".\\cross_val_data\\predictions_noniterative_{i}.csv\", index_col=0)\n",
    "    predictions_iterative = pd.read_csv(fr\".\\cross_val_data\\predictions_iterative_{i}.csv\", index_col=0)\n",
    "    true_data = pd.read_csv(fr\".\\cross_val_data\\true_data_{i}.csv\", index_col=0)\n",
    "\n",
    "    # Initialize lists to hold Bray-Curtis distances for each group\n",
    "    bc_noniterative = []\n",
    "    bc_iterative = []\n",
    "\n",
    "    # Loop through each baboon\n",
    "    for baboon in groups[i].keys():\n",
    "        score_noniter =[] \n",
    "        score_iter =[]\n",
    "        for idx in np.intersect1d(true_data.index, groups[i][baboon].metadata_I.index):\n",
    "            \n",
    "            # Calculate Bray-Curtis scores\n",
    "            score_noniter.append(braycurtis(true_data.loc[idx], predictions_noniterative.loc[idx]))\n",
    "            score_iter.append(braycurtis(true_data.loc[idx], predictions_iterative.loc[idx]))\n",
    "\n",
    "            # Append the scores to respective lists\n",
    "        bc_noniterative.append(np.mean(score_noniter))\n",
    "        bc_iterative.append(np.mean(score_iter))\n",
    "\n",
    "    # Plot KDE plots for both noniterative and iterative scores\n",
    "    sns.kdeplot(bc_noniterative, ax=axes[i, 0], label=\"noniterative\")\n",
    "    sns.kdeplot(bc_iterative, ax=axes[i, 1], label=\"iterative\")\n",
    "    axes[i, 0].set_xlim(0, 1)\n",
    "    axes[i, 1].set_xlim(0, 1)\n",
    "    axes[i, 0].vlines(np.mean(bc_noniterative), 0, 10, color='red', linestyle='--')\n",
    "    axes[i, 1].vlines(np.mean(bc_iterative), 0, 10, color='red', linestyle='--')\n",
    "\n",
    "    # Set titles\n",
    "    axes[i, 0].set_title(f\"Non-iterative (Group {i+1}), mean={np.mean(bc_noniterative):.3f}\")\n",
    "    axes[i, 1].set_title(f\"Iterative (Group {i+1}), mean={np.mean(bc_iterative):.3f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 7))\n",
    "        \n",
    "for i in range(4):\n",
    "    # Load data\n",
    "    predictions_noniterative = pd.read_csv(fr\".\\cross_val_data\\predictions_noniterative_{i}.csv\", index_col=0)\n",
    "    predictions_iterative = pd.read_csv(fr\".\\cross_val_data\\predictions_iterative_{i}.csv\", index_col=0)\n",
    "    true_data = pd.read_csv(fr\".\\cross_val_data\\true_data_{i}.csv\", index_col=0)\n",
    "\n",
    "    # Initialize lists to hold Bray-Curtis distances for each group\n",
    "    bc_noniterative = []\n",
    "    bc_iterative = []\n",
    "\n",
    "    # Loop through each baboon\n",
    "    for baboon in groups[i].keys():\n",
    "        score_noniter =[] \n",
    "        score_iter =[]\n",
    "        for idx in np.intersect1d(true_data.index, groups[i][baboon].metadata_I.index):\n",
    "            \n",
    "            # Calculate Bray-Curtis scores\n",
    "            score_noniter.append(braycurtis(true_data.loc[idx], predictions_noniterative.loc[idx]))\n",
    "            score_iter.append(braycurtis(true_data.loc[idx], predictions_iterative.loc[idx]))\n",
    "\n",
    "            # Append the scores to respective lists\n",
    "        bc_noniterative.append(np.mean(score_noniter))\n",
    "        bc_iterative.append(np.mean(score_iter))\n",
    "\n",
    "\n",
    "    # Plot KDE for non-iterative and iterative results across group\n",
    "    sns.kdeplot(bc_noniterative, ax=axes[0], label=f\"Group {i}, mean={np.mean(bc_noniterative):.3f}\")\n",
    "    sns.kdeplot(bc_iterative, ax=axes[1],  label=f\"Group {i}, mean={np.mean(bc_iterative):.3f}\")\n",
    "\n",
    "# Set titles and labels\n",
    "axes[0].set_title(\"Non-iterative\")\n",
    "axes[1].set_title(\"Iterative\")\n",
    "axes[0].set_xlabel(\"Bray-Curtis Distance\")\n",
    "axes[1].set_xlabel(\"Bray-Curtis Distance\")\n",
    "axes[0].legend()\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only first 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baboons = model.baboons\n",
    "dict_list = list(model.baboons.items())\n",
    "np.random.shuffle(dict_list)\n",
    "groups = [dict(group) for group in np.array_split(dict_list,4)]\n",
    "\n",
    "data_df = pd.read_csv(data_path, index_col=0)\n",
    "metadata_df = pd.read_csv(metadata_path, index_col=0)\n",
    "\n",
    "for i in range(4):\n",
    "    train_metatdata = metadata_df[~metadata_df[\"baboon_id\"].isin(groups[i].keys())]\n",
    "    train_data = data_df.loc[train_metatdata.index]\n",
    "    known_metadata = metadata_df[metadata_df['baboon_id'].isin(groups[i].keys())]\n",
    "    indicies = []\n",
    "    for baboon in groups[i].values():\n",
    "        indicies.extend(baboon.metadata_I.index[:2])\n",
    "\n",
    "    known_data = data_df.loc[indicies]\n",
    "    true_data = data_df.loc[known_metadata[~np.isin(known_metadata.index, indicies)].index]\n",
    "\n",
    "\n",
    "    train_data.to_csv(fr\".\\cross_val_data\\train_data_{i}.csv\")\n",
    "    train_metatdata.to_csv(fr\".\\cross_val_data\\train_metadata_{i}.csv\")\n",
    "    known_data.to_csv(fr\".\\cross_val_data\\known_data_{i}.csv\")\n",
    "    known_metadata.to_csv(fr\".\\cross_val_data\\known_metadata_{i}.csv\")\n",
    "    true_data.to_csv(fr\".\\cross_val_data\\true_data_{i}.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baboons = model.baboons\n",
    "dict_list = list(model.baboons.items())\n",
    "np.random.shuffle(dict_list)\n",
    "groups = [dict(group) for group in np.array_split(dict_list,4)]\n",
    "metadata_df, data_df = social_model_class_v2.preprocessing(data_path, metadata_path)\n",
    "\n",
    "for i in range(4):\n",
    "    train_metatdata = metadata_df[~metadata_df[\"baboon_id\"].isin(groups[i].keys())]\n",
    "    train_data = data_df.loc[train_metatdata.index]\n",
    "    known_metadata = metadata_df[metadata_df['baboon_id'].isin(groups[i].keys())]\n",
    "    indicies = []\n",
    "    for baboon in groups[i].values():\n",
    "        indicies.extend(baboon.metadata_I.index[:2])\n",
    "\n",
    "    known_data = data_df.loc[indicies]\n",
    "    true_data = data_df.loc[known_metadata[~np.isin(known_metadata.index, indicies)].index]\n",
    "\n",
    "\n",
    "    train_data.to_csv(fr\".\\cross_val_data\\train_data_{i}.csv\")\n",
    "    train_metatdata.to_csv(fr\".\\cross_val_data\\train_metadata_{i}.csv\")\n",
    "    known_data.to_csv(fr\".\\cross_val_data\\known_data_{i}.csv\")\n",
    "    known_metadata.to_csv(fr\".\\cross_val_data\\known_metadata_{i}.csv\")\n",
    "    true_data.to_csv(fr\".\\cross_val_data\\true_data_{i}.csv\")\n",
    "    \n",
    "for i in range(4):\n",
    "    model = social_model_class_v2.superModel(fr\".\\cross_val_data\\train_data_{i}.csv\", fr\".\\cross_val_data\\train_metadata_{i}.csv\")\n",
    "    model.alpha_ = np.array([0]*61)\n",
    "    \n",
    "    cpus = max(1, min(multiprocessing.cpu_count() - 2, len(model.baboons)))\n",
    "    with ProcessPoolExecutor(cpus) as executor:\n",
    "        futures = [executor.submit(baboon.fit, model.alpha_) for baboon in model.baboons.values()]\n",
    "        for future in as_completed(futures):\n",
    "            pass\n",
    "    \n",
    "    print(f\"predicting {i}\")\n",
    "    \n",
    "    model.add_new_data(fr\".\\cross_val_data\\known_data_{i}.csv\", fr\".\\cross_val_data\\known_metadata_{i}.csv\")\n",
    "\n",
    "    print(f\"new data added {i}\")\n",
    "    predictions_noniterative = model.predict(groups[i].keys(), iterative=False)\n",
    "    predictions_iterative = model.predict(groups[i].keys(), iterative=True)\n",
    "    predictions_noniterative.to_csv(fr\".\\cross_val_data\\predictions_noniterative_{i}.csv\")\n",
    "    predictions_iterative.to_csv(fr\".\\cross_val_data\\predictions_iterative_{i}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(10, 15))\n",
    "\n",
    "for i in range(4):\n",
    "    # Load data\n",
    "    predictions_noniterative = pd.read_csv(fr\".\\cross_val_data\\predictions_noniterative_{i}.csv\", index_col=0)\n",
    "    predictions_iterative = pd.read_csv(fr\".\\cross_val_data\\predictions_iterative_{i}.csv\", index_col=0)\n",
    "    true_data = pd.read_csv(fr\".\\cross_val_data\\true_data_{i}.csv\", index_col=0)\n",
    "\n",
    "    # Initialize lists to hold Bray-Curtis distances for each group\n",
    "    bc_noniterative = []\n",
    "    bc_iterative = []\n",
    "\n",
    "    # Loop through each baboon\n",
    "    for baboon in groups[i].keys():\n",
    "        score_noniter =[] \n",
    "        score_iter =[]\n",
    "        for idx in np.intersect1d(true_data.index, groups[i][baboon].metadata_I.index):\n",
    "            \n",
    "            # Calculate Bray-Curtis scores\n",
    "            score_noniter.append(braycurtis(true_data.loc[idx], predictions_noniterative.loc[idx]))\n",
    "            score_iter.append(braycurtis(true_data.loc[idx], predictions_iterative.loc[idx]))\n",
    "\n",
    "            # Append the scores to respective lists\n",
    "        bc_noniterative.append(np.mean(score_noniter))\n",
    "        bc_iterative.append(np.mean(score_iter))\n",
    "\n",
    "\n",
    "    # Plot KDE for non-iterative and iterative results across group\n",
    "    sns.kdeplot(bc_noniterative, ax=axes[i, 0], label=\"noniterative\")\n",
    "    sns.kdeplot(bc_iterative, ax=axes[i, 1], label=\"iterative\")\n",
    "    axes[i, 0].set_xlim(0, 1)\n",
    "    axes[i, 1].set_xlim(0, 1)\n",
    "    axes[i, 0].vlines(np.mean(bc_noniterative), 0, 10, color='red', linestyle='--')\n",
    "    axes[i, 1].vlines(np.mean(bc_iterative), 0, 10, color='red', linestyle='--')\n",
    "\n",
    "    # Set titles\n",
    "    axes[i, 0].set_title(f\"Non-iterative (Group {i+1}) Super Short (first 2), mean={np.mean(bc_noniterative):.3f}\")\n",
    "    axes[i, 1].set_title(f\"Iterative (Group {i+1}) Super Short (first 2), mean={np.mean(bc_iterative):.3f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 7))\n",
    "\n",
    "# Initialize lists to accumulate Bray-Curtis distances for all groups\n",
    "bc_noniterative = []\n",
    "bc_iterative = []\n",
    "\n",
    "for i in range(4):\n",
    "    # Load data\n",
    "    predictions_noniterative = pd.read_csv(fr\".\\cross_val_data\\predictions_noniterative_{i}.csv\", index_col=0)\n",
    "    predictions_iterative = pd.read_csv(fr\".\\cross_val_data\\predictions_iterative_{i}.csv\", index_col=0)\n",
    "    true_data = pd.read_csv(fr\".\\cross_val_data\\true_data_{i}.csv\", index_col=0)\n",
    "\n",
    "    # Initialize lists to hold Bray-Curtis distances for each group\n",
    "    bc_noniterative = []\n",
    "    bc_iterative = []\n",
    "\n",
    "    # Loop through each baboon\n",
    "    for baboon in groups[i].keys():\n",
    "        score_noniter =[] \n",
    "        score_iter =[]\n",
    "        for idx in np.intersect1d(true_data.index, groups[i][baboon].metadata_I.index):\n",
    "            \n",
    "            # Calculate Bray-Curtis scores\n",
    "            score_noniter.append(braycurtis(true_data.loc[idx], predictions_noniterative.loc[idx]))\n",
    "            score_iter.append(braycurtis(true_data.loc[idx], predictions_iterative.loc[idx]))\n",
    "\n",
    "            # Append the scores to respective lists\n",
    "        bc_noniterative.append(np.mean(score_noniter))\n",
    "        bc_iterative.append(np.mean(score_iter))\n",
    "\n",
    "\n",
    "    # Plot KDE for non-iterative and iterative results across group\n",
    "    sns.kdeplot(bc_noniterative, ax=axes[0], label=f\"Group {i}, mean={np.mean(bc_noniterative):.3f}\")\n",
    "    sns.kdeplot(bc_iterative, ax=axes[1],  label=f\"Group {i}, mean={np.mean(bc_iterative):.3f}\")\n",
    "\n",
    "# Set titles and labels\n",
    "axes[0].set_title(\"Non-iterative Super Short (first 2)\")\n",
    "axes[1].set_title(\"Iterative Super Short (first 2)\")\n",
    "axes[0].set_xlabel(\"Bray-Curtis Distance\")\n",
    "axes[1].set_xlabel(\"Bray-Curtis Distance\")\n",
    "axes[0].legend()\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all but last 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baboons = model.baboons\n",
    "dict_list = list(model.baboons.items())\n",
    "np.random.shuffle(dict_list)\n",
    "groups = [dict(group) for group in np.array_split(dict_list,4)]\n",
    "\n",
    "data_df = pd.read_csv(data_path, index_col=0)\n",
    "metadata_df = pd.read_csv(metadata_path, index_col=0)\n",
    "\n",
    "for i in range(4):\n",
    "    train_metatdata = metadata_df[~metadata_df[\"baboon_id\"].isin(groups[i].keys())]\n",
    "    train_data = data_df.loc[train_metatdata.index]\n",
    "    known_metadata = metadata_df[metadata_df['baboon_id'].isin(groups[i].keys())]\n",
    "    indicies = []\n",
    "    for baboon in groups[i].values():\n",
    "        indicies.extend(baboon.metadata_I.index[:-10])\n",
    "\n",
    "    known_data = data_df.loc[indicies]\n",
    "    true_data = data_df.loc[known_metadata[~np.isin(known_metadata.index, indicies)].index]\n",
    "\n",
    "\n",
    "    train_data.to_csv(fr\".\\cross_val_data\\train_data_{i}.csv\")\n",
    "    train_metatdata.to_csv(fr\".\\cross_val_data\\train_metadata_{i}.csv\")\n",
    "    known_data.to_csv(fr\".\\cross_val_data\\known_data_{i}.csv\")\n",
    "    known_metadata.to_csv(fr\".\\cross_val_data\\known_metadata_{i}.csv\")\n",
    "    true_data.to_csv(fr\".\\cross_val_data\\true_data_{i}.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baboons = model.baboons\n",
    "dict_list = list(model.baboons.items())\n",
    "np.random.shuffle(dict_list)\n",
    "groups = [dict(group) for group in np.array_split(dict_list,4)]\n",
    "metadata_df, data_df = social_model_class_v2.preprocessing(data_path, metadata_path)\n",
    "\n",
    "for i in range(4):\n",
    "    train_metatdata = metadata_df[~metadata_df[\"baboon_id\"].isin(groups[i].keys())]\n",
    "    train_data = data_df.loc[train_metatdata.index]\n",
    "    known_metadata = metadata_df[metadata_df['baboon_id'].isin(groups[i].keys())]\n",
    "    indicies = []\n",
    "    for baboon in groups[i].values():\n",
    "        indicies.extend(baboon.metadata_I.index[:10])\n",
    "\n",
    "    known_data = data_df.loc[indicies]\n",
    "    true_data = data_df.loc[known_metadata[~np.isin(known_metadata.index, indicies)].index]\n",
    "\n",
    "\n",
    "    train_data.to_csv(fr\".\\cross_val_data\\train_data_{i}.csv\")\n",
    "    train_metatdata.to_csv(fr\".\\cross_val_data\\train_metadata_{i}.csv\")\n",
    "    known_data.to_csv(fr\".\\cross_val_data\\known_data_{i}.csv\")\n",
    "    known_metadata.to_csv(fr\".\\cross_val_data\\known_metadata_{i}.csv\")\n",
    "    true_data.to_csv(fr\".\\cross_val_data\\true_data_{i}.csv\")\n",
    "    \n",
    "for i in range(4):\n",
    "    model = social_model_class_v2.superModel(fr\".\\cross_val_data\\train_data_{i}.csv\", fr\".\\cross_val_data\\train_metadata_{i}.csv\")\n",
    "    model.alpha_ = np.array([0]*61)\n",
    "    \n",
    "    cpus = max(1, min(multiprocessing.cpu_count() - 2, len(model.baboons)))\n",
    "    with ProcessPoolExecutor(cpus) as executor:\n",
    "        futures = [executor.submit(baboon.fit, model.alpha_) for baboon in model.baboons.values()]\n",
    "        for future in as_completed(futures):\n",
    "            pass\n",
    "    \n",
    "    print(f\"predicting {i}\")\n",
    "    \n",
    "    model.add_new_data(fr\".\\cross_val_data\\known_data_{i}.csv\", fr\".\\cross_val_data\\known_metadata_{i}.csv\")\n",
    "\n",
    "    print(f\"new data added {i}\")\n",
    "    predictions_noniterative = model.predict(groups[i].keys(), iterative=False)\n",
    "    predictions_iterative = model.predict(groups[i].keys(), iterative=True)\n",
    "    predictions_noniterative.to_csv(fr\".\\cross_val_data\\predictions_noniterative_{i}.csv\")\n",
    "    predictions_iterative.to_csv(fr\".\\cross_val_data\\predictions_iterative_{i}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(10, 15))\n",
    "\n",
    "for i in range(4):\n",
    "    # Load data\n",
    "    predictions_noniterative = pd.read_csv(fr\".\\cross_val_data\\predictions_noniterative_{i}.csv\", index_col=0)\n",
    "    predictions_iterative = pd.read_csv(fr\".\\cross_val_data\\predictions_iterative_{i}.csv\", index_col=0)\n",
    "    true_data = pd.read_csv(fr\".\\cross_val_data\\true_data_{i}.csv\", index_col=0)\n",
    "\n",
    "    # Initialize lists to hold Bray-Curtis distances for each group\n",
    "    bc_noniterative = []\n",
    "    bc_iterative = []\n",
    "\n",
    "    # Loop through each baboon\n",
    "    for baboon in groups[i].keys():\n",
    "        score_noniter =[] \n",
    "        score_iter =[]\n",
    "        for idx in np.intersect1d(true_data.index, groups[i][baboon].metadata_I.index):\n",
    "            \n",
    "            # Calculate Bray-Curtis scores\n",
    "            score_noniter.append(braycurtis(true_data.loc[idx], predictions_noniterative.loc[idx]))\n",
    "            score_iter.append(braycurtis(true_data.loc[idx], predictions_iterative.loc[idx]))\n",
    "\n",
    "            # Append the scores to respective lists\n",
    "        bc_noniterative.append(np.mean(score_noniter))\n",
    "        bc_iterative.append(np.mean(score_iter))\n",
    "\n",
    "\n",
    "    # Plot KDE for non-iterative and iterative results across group\n",
    "    sns.kdeplot(bc_noniterative, ax=axes[i, 0], label=\"noniterative\")\n",
    "    sns.kdeplot(bc_iterative, ax=axes[i, 1], label=\"iterative\")\n",
    "    axes[i, 0].set_xlim(0, 1)\n",
    "    axes[i, 1].set_xlim(0, 1)\n",
    "    axes[i, 0].vlines(np.mean(bc_noniterative), 0, 3.5, color='red', linestyle='--')\n",
    "    axes[i, 1].vlines(np.mean(bc_iterative), 0, 3.5, color='red', linestyle='--')\n",
    "\n",
    "    # Set titles\n",
    "    axes[i, 0].set_title(f\"Non-iterative (Group {i+1}) Long (all but last 10), mean={np.mean(bc_noniterative):.3f}\")\n",
    "    axes[i, 1].set_title(f\"Iterative (Group {i+1}) Long (all but last 10), mean={np.mean(bc_iterative):.3f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 7))\n",
    "\n",
    "for i in range(4):\n",
    "    # Load data\n",
    "    predictions_noniterative = pd.read_csv(fr\".\\cross_val_data\\predictions_noniterative_{i}.csv\", index_col=0)\n",
    "    predictions_iterative = pd.read_csv(fr\".\\cross_val_data\\predictions_iterative_{i}.csv\", index_col=0)\n",
    "    true_data = pd.read_csv(fr\".\\cross_val_data\\true_data_{i}.csv\", index_col=0)\n",
    "\n",
    "    # Initialize lists to hold Bray-Curtis distances for each group\n",
    "    bc_noniterative = []\n",
    "    bc_iterative = []\n",
    "\n",
    "    # Loop through each baboon\n",
    "    for baboon in groups[i].keys():\n",
    "        score_noniter =[] \n",
    "        score_iter =[]\n",
    "        for idx in np.intersect1d(true_data.index, groups[i][baboon].metadata_I.index):\n",
    "            \n",
    "            # Calculate Bray-Curtis scores\n",
    "            score_noniter.append(braycurtis(true_data.loc[idx], predictions_noniterative.loc[idx]))\n",
    "            score_iter.append(braycurtis(true_data.loc[idx], predictions_iterative.loc[idx]))\n",
    "\n",
    "            # Append the scores to respective lists\n",
    "        bc_noniterative.append(np.mean(score_noniter))\n",
    "        bc_iterative.append(np.mean(score_iter))\n",
    "\n",
    "\n",
    "    # Plot KDE for non-iterative and iterative results across group\n",
    "    sns.kdeplot(bc_noniterative_all, ax=axes[0], label=f\"Group {i}, mean={np.mean(bc_noniterative):.3f}\")\n",
    "    sns.kdeplot(bc_iterative_all, ax=axes[1],  label=f\"Group {i}, mean={np.mean(bc_iterative):.3f}\")\n",
    "\n",
    "# Set titles and labels\n",
    "axes[0].set_title(\"Non-iterative Long (all but last 10)\")\n",
    "axes[1].set_title(\"Iterative Long (all but last 10)\")\n",
    "axes[0].set_xlabel(\"Bray-Curtis Distance\")\n",
    "axes[1].set_xlabel(\"Bray-Curtis Distance\")\n",
    "axes[0].legend()\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
